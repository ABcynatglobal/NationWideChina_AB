{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required translator package \n",
    "!pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "# Load the CSV file\n",
    "input_file = \"CarOwnersChina.csv.csv\"  # Replace with your file path\n",
    "df = pd.read_csv(input_file, low_memory=False)\n",
    "\n",
    "# Initialize the Google Translator\n",
    "translator = GoogleTranslator(source='auto', target='en')\n",
    "\n",
    "# Translate the column headers from Chinese to English\n",
    "translated_columns = [translator.translate(col) for col in df.columns]\n",
    "\n",
    "# Replace the column headers with the translated ones\n",
    "df.columns = translated_columns\n",
    "\n",
    "# Save the translated DataFrame to a new CSV file\n",
    "output_file = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CarOwners_translated.csv\"  # Replace with your desired output path\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Translation of column headers complete. Saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Read the initial CSV file with separator modification and low memory usage\n",
    "try:\n",
    "    df = pd.read_csv('CarOwners_translated.csv', low_memory=False)\n",
    "    if df.empty:\n",
    "        print(\"Warning: The input CSV file is empty.\")\n",
    "    else:\n",
    "        print(\"CSV file loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'CarOwners_translated.csv' was not found.\")\n",
    "    sys.exit(1)\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty.\")\n",
    "    sys.exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Define a function to merge Province, City, and Address into a new column \"Full Address\"\n",
    "def merge_address_columns(df):\n",
    "    \"\"\"\n",
    "    Merges 'Province', 'City', and 'Address' columns into a new 'Full Address' column.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the address information.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The DataFrame with the new 'Full Address' column.\n",
    "    \"\"\"\n",
    "    df['Full Address'] = df['Province'].fillna('').astype(str) + ', ' + df['City'].fillna('').astype(str) + ', ' + df['address'].fillna('').astype(str) + ', ' + df['post code'].fillna('').astype(str)\n",
    "    df['Full Address'] = df['Full Address'].str.replace(r'(^, |, $)', '', regex=True)  # Clean up any leading/trailing commas\n",
    "\n",
    "    # Store the columns to be dropped in a separate DataFrame\n",
    "    garbage_df = df[['Province', 'City', 'address', 'post code', 'Monthly salary', 'marriage', 'educate', 'color', 'gender', 'Birthday', 'industry', 'Unnamed: 21']].copy()\n",
    "\n",
    "    # Drop the original columns\n",
    "    df.drop(columns=['Province', 'City', 'address', 'post code', 'Monthly salary', 'marriage', 'educate', 'color', 'gender', 'Birthday', 'industry', 'Unnamed: 21'], inplace=True)\n",
    "  \n",
    "    return df, garbage_df\n",
    "\n",
    "# Merge the address columns and get the garbage DataFrame\n",
    "df, garbage_df = merge_address_columns(df)\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'Mail': 'Email', 'Engine No.': 'Engine Number', 'ID card': 'ID Number'}, inplace=True)\n",
    "\n",
    "def save_dataframe_to_csv(df, file_path):\n",
    "    \"\"\"\n",
    "    Saves a pandas DataFrame to a CSV file at the specified file path.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame to save.\n",
    "    file_path (str): The file path where the CSV file will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sys.setrecursionlimit(10000)  # Increase recursion limit if necessary (use caution)\n",
    "        \n",
    "        if df.empty:\n",
    "            print(\"Warning: The DataFrame is empty. No file will be saved.\")\n",
    "        else:\n",
    "            df.to_csv(file_path, index=False)\n",
    "            print(f\"File saved successfully to {file_path}\")\n",
    "    except RecursionError as rec_err:\n",
    "        print(f\"Recursion error encountered: {rec_err}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Usage example\n",
    "cleaned_file_path = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CleanedCarOwners\\CleaningCarOwners.csv\"  # Use raw string for file paths\n",
    "garbage_file_path = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CleanedCarOwners\\Garbage\\DroppedColumns.csv\"  # Path for garbage file\n",
    "\n",
    "# Save DataFrame to the file\n",
    "save_dataframe_to_csv(df, cleaned_file_path)\n",
    "\n",
    "# Save the garbage DataFrame to a separate file\n",
    "save_dataframe_to_csv(garbage_df, garbage_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import warnings \n",
    "\n",
    "# Suppress FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    " \n",
    "# Function to validate email format (must be alphanumeric before the @)\n",
    "def is_valid_email(email):\n",
    "    if not isinstance(email, str):\n",
    "        return False \n",
    "    email_regex = r'^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$'\n",
    "    return re.match(email_regex, email) is not None and bool(re.search(r'[a-zA-Z0-9]', email.split('@')[0]))\n",
    "\n",
    "# Function to process the CSV file\n",
    "def process_csv(input_file, garbage_file, cleaned_file):\n",
    "    # Read the CSV file into a DataFrame with low_memory=False\n",
    "    df = pd.read_csv(input_file, low_memory=False)\n",
    "\n",
    "    # Create a garbage DataFrame for invalid/duplicate rows\n",
    "    garbage_df = pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    # Check for invalid emails (non-alphanumeric characters in the local part or incorrect format)\n",
    "    invalid_email_rows = df[~df['Email'].apply(is_valid_email)]\n",
    "\n",
    "    # Append invalid email rows to the garbage DataFrame\n",
    "    if not invalid_email_rows.empty:\n",
    "        garbage_df = pd.concat([garbage_df, invalid_email_rows])\n",
    "\n",
    "    # Drop invalid email rows from the original DataFrame\n",
    "    df = df.drop(invalid_email_rows.index)\n",
    "\n",
    "    # Check for duplicate Emails, ID Numbers, Frame numbers,\n",
    "    duplicates = df[df.duplicated(subset=['Email', 'ID Number', 'Frame number',], keep = 'first')]\n",
    "\n",
    "    # Append duplicate rows to the garbage DataFrame\n",
    "    if not duplicates.empty:\n",
    "        garbage_df = pd.concat([garbage_df, duplicates])\n",
    "\n",
    "    # Drop duplicate rows from the original DataFrame\n",
    "    df = df.drop(duplicates.index)\n",
    "\n",
    "   # Replace specific emails with 'Null'\n",
    "    df['Email'] = df['Email'].replace({\n",
    "        'noemail@email.com': 'Null',\n",
    "        'nomail@mail.com': 'Null',\n",
    "        'noema@email.com': 'Null'\n",
    "    })\n",
    "\n",
    "    # Save the garbage DataFrame to a CSV file\n",
    "    garbage_df.to_csv(garbage_file, index=False)\n",
    "\n",
    "    print(f\"Invalid and duplicate rows have been saved to {garbage_file}\")\n",
    "     \n",
    "    # Save the cleaned data (valid rows) to a new CSV file\n",
    "    df.to_csv(cleaned_file, index=False)\n",
    "    print(f\"Cleaned data has been saved to {cleaned_file}\")\n",
    "\n",
    "# Example usage\n",
    "input_file = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CleanedCarOwners\\CleaningCarOwners.csv\"# Path to your input CSV file\n",
    "garbage_file = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CleanedCarOwners\\Garbage\\InvalidRows2.csv\"   # Path where you want to save the invalid/duplicate rows\n",
    "cleaned_file = r\"C:\\Users\\PROTEXXA\\Desktop\\NationWideChina\\CleanedCarOwners\\CleanedCarOwner2.csv\"  # Path where you want to save the cleaned data\n",
    "\n",
    "process_csv(input_file, garbage_file, cleaned_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
